{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMs+T4USVrWbndqeehEsq3q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "yl5-tp8xSfW4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qC6g3gdabdDN"
      },
      "outputs": [],
      "source": [
        "class VitInputLayer(nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      in_channels:int=3,\n",
        "      emb_dim:int=384,\n",
        "      num_patch_row:int=2,\n",
        "      image_size:int=32\n",
        "      ):\n",
        "\n",
        "    '''\n",
        "      in_channels:入力画像のチャネル数\n",
        "      emb_dim:埋め込み後のベクトルの長さ\n",
        "      num_patch_row:高さ方向のバッチの数\n",
        "      image_size:入力画像の1辺の長さ\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.emb_dim = emb_dim\n",
        "    self.num_patch_row = num_patch_row\n",
        "    self.image_size = image_size\n",
        "\n",
        "    # パッチの面積\n",
        "    self.num_patch = self.num_patch_row * self.num_patch_row\n",
        "    # パッチの大きさ(画像サイズ/パッチ1辺の長さ)\n",
        "    self.patch_size = int(self.image_size / self.num_patch_row)\n",
        "\n",
        "    # 入力画像のパッチ分割 & パッチの埋め込み\n",
        "    self.patch_emb_layer = nn.Conv2d(\n",
        "        in_channels=self.in_channels,\n",
        "        out_channels=self.emb_dim,\n",
        "        kernel_size=self.patch_size,\n",
        "        stride=self.patch_size\n",
        "    )\n",
        "\n",
        "    # クラストークン\n",
        "    self.cls_token = nn.Parameter(torch.rand(1,1,emb_dim))\n",
        "\n",
        "    # 位置埋め込み\n",
        "    self.pos_emb = nn.Parameter(torch.rand(1,self.num_patch+1,emb_dim))\n",
        "\n",
        "  def forward(self,x:torch.Tensor) -> torch.Tensor:\n",
        "    '''\n",
        "      引数:\n",
        "        x:入力画像.(B,C,H,W)\n",
        "\n",
        "      返り値:\n",
        "        z_0:ViTに入力する特徴量.(B,N,emb_dim)\n",
        "          B:パッチサイズ　N:トークン数　emb_dim:埋め込み後のベクトルの長さ\n",
        "    '''\n",
        "\n",
        "    # (B,C,H,W) -> (B,D,H/P,W/P)\n",
        "    # P:バッチ1辺の長さ\n",
        "    z_0 = self.patch_emb_layer(x)\n",
        "    print(z_0.shape)\n",
        "    # パッチのflatten. (B,D,H/P,W/P) -> (B,D,Np)\n",
        "    # Npはパッチの数(H*W/P^2)\n",
        "    # 2を指定することで2次元目から後ろの次元をすべて1次元にまとめる\n",
        "    z_0 = z_0.flatten(2)\n",
        "\n",
        "    # 軸の入れ替え (B,D,Np) -> (B,Np,D)\n",
        "    z_0 = z_0.transpose(1,2)\n",
        "\n",
        "    # 埋め込みの先頭にクラストークンを結合\n",
        "    # (B,Np,D) -> (B,Np+1,D)\n",
        "    # クラストークンは(1,1,D)なのでリピートで(B,1,D)\n",
        "    z_0 = torch.cat([self.cls_token.repeat(repeats=(x.shape[0],1,1)),z_0],dim=1)\n",
        "\n",
        "    # 位置埋め込み\n",
        "    z_0 = z_0 + self.pos_emb\n",
        "\n",
        "    return z_0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size,channel,height,width=2,3,32,32\n",
        "x=torch.rand(batch_size,channel,height,width)\n",
        "vit_input_layer=VitInputLayer()\n",
        "z_0=vit_input_layer(x)\n",
        "print(z_0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOSFYHh9gHzg",
        "outputId": "6bbc4e3d-95de-4a6d-ad19-19ab1f753040"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 384, 2, 2])\n",
            "torch.Size([2, 5, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "  def __init__(self,emb_dim:int=384,head:int=3,dropout:float=0.0):\n",
        "    '''\n",
        "      emb_dim:埋め込み後のベクトルの長さ\n",
        "      head:ヘッドの数\n",
        "      dropout:ドロップアウト率\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.head = head\n",
        "    self.emb_dim = emb_dim\n",
        "    self.head_dim = emb_dim//head\n",
        "    self.sqrt_dh = self.head_dim**0.5 # Dhの二乗根\n",
        "\n",
        "    # 入力をq,k,vに埋め込むための線形層\n",
        "    self.w_q = nn.Linear(emb_dim,emb_dim,bias=False)\n",
        "    self.w_k = nn.Linear(emb_dim,emb_dim,bias=False)\n",
        "    self.w_v = nn.Linear(emb_dim,emb_dim,bias=False)\n",
        "    self.attn_drop = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    # MHSAを埋め込むための線形層\n",
        "    self.w_o = nn.Sequential(\n",
        "        nn.Linear(emb_dim,emb_dim),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self,z:torch.Tensor) -> torch.Tensor:\n",
        "    '''\n",
        "      引数:\n",
        "        z:MHSAに入力する特徴量.(B,N,D)\n",
        "          B:バッチサイズ　N:トークン数　D:ベクトルの長さ\n",
        "      返り値:\n",
        "        z:MHSAを出力する特徴量.(B,N,D)\n",
        "          B:パッチサイズ　N:トークン数　emb_dim:埋め込み後のベクトルの長さ\n",
        "    '''\n",
        "\n",
        "    batch_size,num_patch,_ = z.shape\n",
        "\n",
        "    # 埋め込み\n",
        "    q = self.w_q(z)\n",
        "    k = self.w_k(z)\n",
        "    v = self.w_v(z)\n",
        "\n",
        "    # ヘッドに分ける\n",
        "    # (B,N,D) -> (B,N,h,D//h)\n",
        "    q = q.view(batch_size,num_patch,self.head,self.head_dim)\n",
        "    k = k.view(batch_size,num_patch,self.head,self.head_dim)\n",
        "    v = v.view(batch_size,num_patch,self.head,self.head_dim)\n",
        "\n",
        "    # 形の変更(ヘッドごとに操作するため)\n",
        "    # (B,N,h,D//h) -> (B,h,N,D//h)\n",
        "    q = q.transpose(1,2)\n",
        "    k = k.transpose(1,2)\n",
        "    v = v.transpose(1,2)\n",
        "\n",
        "    # ヘッドの転置(行列積を取るため)\n",
        "    # (B,h,N,D//h) -> (B,h,D//h,N)\n",
        "    k_T=k.transpose(2,3)\n",
        "\n",
        "    # (B, h, N, D//h) x (B, h, D//h, N) -> (B, h, N, N)\n",
        "    dots = (q @ k_T) / self.sqrt_dh\n",
        "\n",
        "    # 列方向にsoftmax\n",
        "    attn = F.softmax(dots,dim=-1)\n",
        "\n",
        "    # ドロップアウト\n",
        "    attn = self.attn_drop(attn)\n",
        "\n",
        "\n",
        "    # 加重和\n",
        "    # (B, h, N, N) x (B, h, N, D//h) -> (B, h, N, D//h)\n",
        "    out = attn @ v\n",
        "\n",
        "    # (B, h, N, D//h) -> (B, N, h, D//h) (headを結合するため)\n",
        "    out = out.transpose(1,2)\n",
        "\n",
        "    # (B, N, h, D//h) -> (B,N,D)　結合\n",
        "    out = out.reshape(batch_size,num_patch,self.emb_dim)\n",
        "\n",
        "    # 出力層\n",
        "    out = self.w_o(out)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "BQESpf6_oUcg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mhsa = MultiHeadSelfAttention()\n",
        "out = mhsa(z_0)\n",
        "\n",
        "print(z_0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGmjVecuZVG_",
        "outputId": "ddb9b8c7-3bb8-4f51-d2b0-b9b59f6cdec1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTEncoderBlock(nn.Module):\n",
        "  def __init__(self,emb_dim:int=384,head:int=3,hidden_dim:int=384*4,dropout:float=0.0):\n",
        "    '''\n",
        "      emb_dim:埋め込み後のベクトルの長さ\n",
        "      head:ヘッドの数\n",
        "      hidden_dim:隠れ層の次元 (MLPにおける中間層のベクトルの長さ)\n",
        "      dropout:ドロップアウト率\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.ln1 = nn.LayerNorm(emb_dim)\n",
        "    self.msa = MultiHeadSelfAttention(emb_dim=emb_dim,head=head,dropout=dropout)\n",
        "\n",
        "    self.ln2 = nn.LayerNorm(emb_dim)\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(emb_dim,hidden_dim),\n",
        "        nn.GELU(),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(hidden_dim,emb_dim),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self,z: torch.Tensor) -> torch.Tensor:\n",
        "    '''\n",
        "      引数:\n",
        "        z:ViTEncoderBlockに入力する特徴量.(B,N,D)\n",
        "          B:バッチサイズ　N:トークン数　D:ベクトルの長さ\n",
        "      返り値:\n",
        "        out:ViTEncoderBlockへの出力する特徴量.(B,N,D)\n",
        "          B:バッチサイズ　N:トークン数　D:ベクトルの長さ\n",
        "  　'''\n",
        "    out = self.msa(self.ln1(z)) + z\n",
        "    out = self.mlp(self.ln2(out)) + out\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "Ro8D2-6go3uA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit_enc = ViTEncoderBlock()\n",
        "out = vit_enc(z_0)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwhDpD8OZgFA",
        "outputId": "0819a13e-3328-4137-e946-c6a3d4650753"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "  def __init__(self,in_channels:int=3,num_classes:int=10,emb_dim:int=384,num_patch_row:int=2,image_size:int=32,num_blocks:int=7,head:int=8,hidden_dim:int=384*4,dropout:float=0.0):\n",
        "    '''\n",
        "      in_channels:入力画像のチャネル数\n",
        "      num_classes:分類クラスの数\n",
        "      emb_dim:埋め込み後のベクトルの長さ\n",
        "      num_patch_row:高さ方向のバッチの数\n",
        "      image_size:入力画像の1辺の長さ\n",
        "      num_blocks:ViTのブロック数\n",
        "      head:ヘッドの数\n",
        "      hidden_dim:隠れ層の次元 (MLPにおける中間層のベクトルの長さ)\n",
        "      dropout:ドロップアウト率\n",
        "    '''\n",
        "\n",
        "    super().__init__()\n",
        "    self.input_layer = VitInputLayer(in_channels=in_channels,emb_dim=emb_dim,num_patch_row=num_patch_row,image_size=image_size)\n",
        "\n",
        "    self.encoder = nn.Sequential(*[ViTEncoderBlock(emb_dim=emb_dim,head=head,hidden_dim=hidden_dim,dropout=dropout) for _ in range(num_blocks)])\n",
        "\n",
        "    self.mlp_head = nn.Sequential(\n",
        "        nn.LayerNorm(emb_dim),\n",
        "        nn.Linear(emb_dim,num_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self,x:torch.Tensor) -> torch.Tensor:\n",
        "    '''\n",
        "      引数:\n",
        "        x:ViTに入力する特徴量.(B,C,H,W)\n",
        "          B:バッチ C:チャネル数 H:高さ W:幅\n",
        "      返り値:\n",
        "        out:ViTの出力する特徴量.(B,num_classes)\n",
        "          B:バッチ num_classes:分類クラスの数\n",
        "    '''\n",
        "    out = self.input_layer(x)\n",
        "    out = self.encoder(out)\n",
        "    cls_token = out[:,0] # 最初の行だけ取り出す\n",
        "    out = self.mlp_head(cls_token)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "9ol0raAZrOT9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "batch_size,channel,height,width=2,3,32,32\n",
        "x=torch.rand(batch_size,channel,height,width)\n",
        "vit = ViT(in_channels=channel,num_classes=num_classes)\n",
        "out = vit(x)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmWrKr6uwA1P",
        "outputId": "5edb11e7-df9e-4353-f2b5-7382f85e6c9c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 384, 2, 2])\n",
            "torch.Size([2, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ok8DroxDwRxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}