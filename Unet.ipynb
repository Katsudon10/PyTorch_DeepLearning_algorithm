{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3YNqjc0Dm5DXnsKDwV1Bw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liEnoG5Jg_6W",
        "outputId": "9bf5fbd2-705c-4b60-f080-a438e492d43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 387, 387])\n",
            "tensor([[[[ 0.0182,  0.0133,  0.0200,  ...,  0.0208,  0.0231,  0.0165],\n",
            "          [ 0.0180,  0.0178,  0.0178,  ...,  0.0162,  0.0201,  0.0189],\n",
            "          [ 0.0195,  0.0185,  0.0203,  ...,  0.0224,  0.0198,  0.0206],\n",
            "          ...,\n",
            "          [ 0.0152,  0.0166,  0.0152,  ...,  0.0222,  0.0175,  0.0189],\n",
            "          [ 0.0175,  0.0211,  0.0163,  ...,  0.0192,  0.0117,  0.0212],\n",
            "          [ 0.0172,  0.0185,  0.0171,  ...,  0.0192,  0.0194,  0.0252]],\n",
            "\n",
            "         [[ 0.0031,  0.0057,  0.0121,  ...,  0.0045,  0.0058,  0.0102],\n",
            "          [-0.0013,  0.0045,  0.0005,  ...,  0.0080,  0.0023,  0.0048],\n",
            "          [ 0.0046,  0.0024,  0.0039,  ...,  0.0066,  0.0030,  0.0053],\n",
            "          ...,\n",
            "          [-0.0004,  0.0059,  0.0053,  ...,  0.0053,  0.0087,  0.0048],\n",
            "          [-0.0005,  0.0014,  0.0031,  ...,  0.0029,  0.0026,  0.0019],\n",
            "          [ 0.0022,  0.0061,  0.0036,  ...,  0.0057,  0.0086,  0.0024]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def double_conv(in_channel,out_channel):\n",
        "    conv=nn.Sequential(\n",
        "        nn.Conv2d(in_channel,out_channel,kernel_size=3),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channel,out_channel,kernel_size=3),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "    return conv\n",
        "\n",
        "\n",
        "\n",
        "def crop_img(tensor,target_tensor): #change img_size to target_tensor\n",
        "    target_size=target_tensor.size()[2]  #[2] in torch.Size([1, 512, 56, 56]) \n",
        "    tensor_size=tensor.size()[2]    #[2] in torch.Size([1, 512, 56, 56])\n",
        "    delta=tensor_size-target_size\n",
        "    delta=delta//2\n",
        "    return tensor[:,:,delta:tensor_size-delta,delta:tensor_size-delta]\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Unet,self).__init__()\n",
        "    \n",
        "        self.max_pool_2x2=nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.down_conv_1=double_conv(1,64)\n",
        "        self.down_conv_2=double_conv(64,128)\n",
        "        self.down_conv_3=double_conv(128,256)\n",
        "        self.down_conv_4=double_conv(256,512)\n",
        "        self.down_conv_5=double_conv(512,1024)\n",
        "\n",
        "        self.up_trans_1=nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=2,stride=2)\n",
        "        self.up_conv_1=double_conv(1024,512)\n",
        "\n",
        "        self.up_trans_2=nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=2,stride=2)\n",
        "        self.up_conv_2=double_conv(512,256)\n",
        "\n",
        "        self.up_trans_3=nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=2,stride=2)\n",
        "        self.up_conv_3=double_conv(256,128)\n",
        "\n",
        "        self.up_trans_4=nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=2,stride=2)\n",
        "        self.up_conv_4=double_conv(128,64)\n",
        "\n",
        "        self.out=nn.Conv2d(in_channels=64,out_channels=2,kernel_size=2)\n",
        "        \n",
        "    def forward(self,image):\n",
        "        #encoder\n",
        "        x1=self.down_conv_1(image)\n",
        "        x2=self.max_pool_2x2(x1)\n",
        "        x3=self.down_conv_2(x2)\n",
        "        x4=self.max_pool_2x2(x3)\n",
        "        x5=self.down_conv_3(x4)\n",
        "        x6=self.max_pool_2x2(x5)\n",
        "        x7=self.down_conv_4(x6)\n",
        "        x8=self.max_pool_2x2(x7)\n",
        "        x9=self.down_conv_5(x8)\n",
        "        #print(x9.size()) #channel=1 ,image_size=28x28 ,filter_size=1024\n",
        "\n",
        "        #decoder\n",
        "        x=self.up_trans_1(x9)\n",
        "        y=crop_img(x7,x)\n",
        "        x=self.up_conv_1(torch.cat([x,y],1))\n",
        "\n",
        "        x=self.up_trans_2(x)\n",
        "        y=crop_img(x5,x)\n",
        "        x=self.up_conv_2(torch.cat([x,y],1))\n",
        "\n",
        "        x=self.up_trans_3(x)\n",
        "        y=crop_img(x3,x)\n",
        "        x=self.up_conv_3(torch.cat([x,y],1))\n",
        "\n",
        "        x=self.up_trans_4(x)\n",
        "        y=crop_img(x1,x)\n",
        "        x=self.up_conv_4(torch.cat([x,y],1))\n",
        "\n",
        "        x=self.out(x)\n",
        "        print(x.size())\n",
        "        return x\n",
        "        \n",
        "        \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image=torch.rand((1,1,572,572))\n",
        "    model=Unet()\n",
        "    print(model(image))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgLCim8T5AJK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}